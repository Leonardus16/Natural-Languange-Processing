# -*- coding: utf-8 -*-
"""NLP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BESDpzb1AFbs5C-9Z5ReL-R4shFVh1D2
"""

!pip install transformers
!pip install torch
!pip install datasets
# Install the necessary libraries
!pip install transformers pandas tabulate
!pip install openai transformers prettytable

"""**Zero shot dengan GPT-Neo oleh EleutherAI**"""

from transformers import pipeline
from prettytable import PrettyTable

# Load the GPT-3-like model (e.g., GPT-3.5 Turbo)
generator = pipeline('text-generation', model='EleutherAI/gpt-neo-2.7B')

# Define some complex prompts
prompts = [
    "Summarize the plot of the movie 'The Shawshank Redemption'.",
    "Give some tips for improving public speaking skills.",
    "Explain the concept of gravity in basic terms.",
    "Write a brief review of the book 'Harry Potter and the Sorcerer's Stone'.",
    "Translate the following English text to Spanish: 'How are you doing today?'"
]

# Table for prompt results
prompting_table = PrettyTable()
prompting_table.field_names = ["Prompt", "Response"]

# Generate and print responses for each prompt
for prompt in prompts:
    response = generator(prompt, max_length=100, num_return_sequences=1)
    prompting_table.add_row([prompt, response[0]['generated_text']])

print(prompting_table)

from transformers import GPT2LMHeadModel, GPT2Tokenizer
from prettytable import PrettyTable
import re

# Load GPT-2 model and tokenizer
model_name = "gpt2"
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# Define some prompts
prompts = [
    "Summarize the plot of the movie 'The Shawshank Redemption'.",
    "Give some tips for improving public speaking skills.",
    "Explain the concept of gravity in basic terms.",
    "Write a brief review of the book 'Harry Potter and the Sorcerer's Stone'.",
    "Describe the impact of climate change on global biodiversity."
]

# Function to trim text to a certain length
def trim_text(text, max_length):
    return text if len(text) <= max_length else text[:max_length] + '...'

# Table for prompt results
prompting_table = PrettyTable()
prompting_table.field_names = ["Prompt", "Response"]
prompting_table.max_width = 80  # Set maximum width for columns
prompting_table.padding_width = 1  # Set padding width

# Generate and print responses for each prompt
for prompt in prompts:
    # Tokenize the input prompt
    inputs = tokenizer(prompt, return_tensors="pt")

    # Generate text based on the input prompt
    outputs = model.generate(inputs["input_ids"], max_length=100, num_return_sequences=1)
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    trimmed_response = trim_text(generated_text, 150)  # Trim response text if too long
    prompting_table.add_row([prompt, trimmed_response])

# Print the table with prompting results
print(prompting_table)

"""**Zero shot dengan BERT**"""

from transformers import BertTokenizer, BertForSequenceClassification, pipeline
from prettytable import PrettyTable
import torch

# Load model dan tokenizer BERT
model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name)

# Contoh review untuk dianalisis sentimennya
reviews = [
    "This movie was absolutely fantastic, I loved every minute of it!",
    "The product arrived late and was not what I expected, very disappointed.",
    "I have mixed feelings about this book, some parts were great but others were boring.",
    "The restaurant had amazing food but terrible service, overall a mixed experience.",
    "The customer service was excellent, they were very helpful and friendly.",
    "I enjoyed reading this novel, the characters were well-developed and the plot was engaging.",
    "The quality of the product was poor, it broke after only a few uses.",
    "This hotel exceeded my expectations, the room was spacious and clean, and the staff was very accommodating.",
    "The performance of this laptop is disappointing, it's slow and frequently crashes.",
    "I had a wonderful experience at this spa, the massage was incredibly relaxing and the atmosphere was tranquil."
]

# Fungsi untuk melakukan analisis sentimen menggunakan BERT
def analyze_sentiment(model, tokenizer, text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    logits = outputs.logits.detach().cpu().numpy()[0]
    predicted_class = logits.argmax()
    label = 'positive' if predicted_class == 1 else 'negative'
    score = torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()[0]
    return label, score

# Tabel untuk hasil analisis sentimen
sentiment_table = PrettyTable()
sentiment_table.field_names = ["Review", "Sentiment", "Positive Score", "Negative Score"]
sentiment_table.max_width = 30  # Set maximum width for columns
sentiment_table.padding_width = 1  # Set padding width

# Lakukan analisis sentimen untuk setiap review dan tambahkan hasilnya ke dalam tabel
for review in reviews:
    sentiment, scores = analyze_sentiment(model, tokenizer, review)
    positive_score = round(scores[1], 4)
    negative_score = round(scores[0], 4)
    sentiment_table.add_row([review, sentiment, positive_score, negative_score])

# Print tabel hasil analisis sentimen
print(sentiment_table)

"""**Few shot dengan BERT**"""

from transformers import BertTokenizer, BertForSequenceClassification, get_scheduler
from prettytable import PrettyTable
import torch
from torch.utils.data import DataLoader, TensorDataset, random_split

# Load model and tokenizer BERT
model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name)

# Few-shot examples
few_shot_examples = [
    ("positive", "I loved the new movie, it was amazing!"),
    ("negative", "The product I purchased was disappointing, it didn't meet my expectations."),
    ("positive", "The book I read was captivating, I couldn't put it down."),
    ("negative", "The service at the restaurant was terrible, I won't be going back."),
    ("positive", "The scenery was breathtaking and I had a great time."),
    ("negative", "The delivery was late and the package was damaged."),
    ("positive", "I enjoyed the play, it was well-acted and entertaining."),
    ("negative", "The weather ruined our plans, it was rainy and cold."),
    ("positive", "The hotel stay was comfortable and the staff was friendly."),
    ("negative", "The device stopped working after a week of use."),
    ("positive", "The online course was very informative and engaging."),
    ("negative", "The internet connection was unreliable and slow."),
]

# New texts to classify with their expected sentiments
texts_with_sentiments = [
    ("The new smartphone model is fantastic, it exceeds all my expectations.", "positive"),
    ("I had a terrible experience with the airline, the flight was delayed and the staff were rude.", "negative"),
    ("The concert I attended last night was incredible, the band put on an amazing show.", "positive"),
    ("The quality of the food at the restaurant was excellent, I highly recommend it to others.", "positive"),
    ("The customer service I received was exceptional, they went above and beyond to help me.", "positive"),
    ("The latest software update has caused numerous issues, I regret installing it.", "negative"),
    ("The movie I watched last night was disappointing, the plot was weak and the acting was subpar.", "negative"),
    ("I had a great time at the theme park, the rides were thrilling and the atmosphere was lively.", "positive"),
    ("The new product release has generated a lot of buzz, people are excited to try it out.", "positive"),
    ("The hotel I stayed at during my vacation was excellent, the room was clean and comfortable.", "positive"),
]

def analyze_sentiment_few_shot(model, tokenizer, few_shot_examples, texts_with_sentiments):
    # Encode few-shot examples
    labels = [example[0] for example in few_shot_examples]
    texts = [example[1] for example in few_shot_examples]
    encoded_inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
    input_ids = encoded_inputs['input_ids']
    attention_masks = encoded_inputs['attention_mask']

    # Convert labels to numerical format
    label_map = {"positive": 1, "negative": 0}
    labels = torch.tensor([label_map[label] for label in labels])

    # Create DataLoader
    dataset = TensorDataset(input_ids, attention_masks, labels)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    train_dataloader = DataLoader(train_dataset, batch_size=2)
    val_dataloader = DataLoader(val_dataset, batch_size=2)

    # Fine-tune the model with few-shot examples
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
    num_training_steps = 10 * len(train_dataloader)  # Train for more epochs if necessary
    lr_scheduler = get_scheduler(
        name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)
    model.train()
    for epoch in range(10):  # Train for 10 epochs
        for batch in train_dataloader:
            batch_input_ids, batch_attention_masks, batch_labels = batch
            optimizer.zero_grad()
            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, labels=batch_labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            lr_scheduler.step()

    # Classify new texts
    results_table = PrettyTable()
    results_table.field_names = ["Text", "Predicted Sentiment", "Expected Sentiment", "Correct"]
    correct_predictions = 0
    for text, expected_sentiment in texts_with_sentiments:
        encoded_text = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
        with torch.no_grad():
            outputs_text = model(**encoded_text)

        predicted_class = torch.argmax(outputs_text.logits[0]).item()
        predicted_sentiment = "positive" if predicted_class == 1 else "negative"
        correct = "Yes" if predicted_sentiment == expected_sentiment else "No"
        if correct == "Yes":
            correct_predictions += 1
        results_table.add_row([text, predicted_sentiment, expected_sentiment, correct])

    accuracy = correct_predictions / len(texts_with_sentiments)
    return results_table, accuracy

# Perform few-shot sentiment analysis
results_table, accuracy = analyze_sentiment_few_shot(model, tokenizer, few_shot_examples, texts_with_sentiments)

# Print few-shot examples
few_shot_table = PrettyTable()
few_shot_table.field_names = ["Label", "Text"]
for label, text in few_shot_examples:
    few_shot_table.add_row([label, text])

print("Few-shot Examples:")
print(few_shot_table)

# Print classification results
print("\nClassification Results:")
print(results_table)
print(f"\nAccuracy: {accuracy:.2f}")